{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb14571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import pytz\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e13ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grants = pd.read_excel('gr15_grants.xlsx')\n",
    "\n",
    "gr_aplic = pd.read_json('grants_applications_gr15.json').T\n",
    "\n",
    "df  = gr_aplic.merge(grants, on = 'grant_id' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db7f5e63",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['grant_id', 'active_x', 'approved', 'address_x', 'title_x', 'url',\n",
       "       'description_x', 'created_on_x', 'active_y', 'title_y', 'address_y',\n",
       "       'amount_received', 'amount_received_in_round', 'contribution_count',\n",
       "       'contributor_count', 'description_y', 'website', 'github_project_url',\n",
       "       'twitter_handle_2', 'twitter_handle_1', 'twitter_verified',\n",
       "       'created_on_y', 'last_update'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "395a8e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## functions \n",
    "\n",
    "\n",
    "def github_code_stats( owner, repo):\n",
    "    url = \"https://api.github.com/repos/{owner}/{repo}/stats/code_frequency\"\n",
    "    headers = {\n",
    "     'X-GitHub-Api-Version': '2022-11-28', \n",
    "     'accept':'application/vnd.github+json'}\n",
    "    \n",
    "\n",
    "    return { 'status_code':requests.get(url.format(owner=owner, repo=repo), headers=headers).status_code , \n",
    "            'repo_data' : requests.get(url.format(owner=owner, repo=repo), headers=headers).json()}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## get the owner and the repo name of projects github urls, used on the 'start_stats_aggregation' function return a df\n",
    "def get_owner_repo(github_urls):\n",
    "    \n",
    "    owner = []\n",
    "    repo = []\n",
    "    url = []\n",
    "\n",
    "\n",
    "    for i in github_urls:\n",
    "        try:\n",
    "            if i.split('/')[2] == 'github.com':\n",
    "                try:\n",
    "                    if type(i.split('/')[4]) == str:\n",
    "                        repo.append(i.split('/')[4])\n",
    "                        owner.append(i.split('/')[3])\n",
    "                        url.append(i)\n",
    "\n",
    "                except IndexError:\n",
    "                    # Handle the IndexError when the split method doesn't produce enough elements\n",
    "                    repo.append(None)\n",
    "                    owner.append(None)\n",
    "                    url.append(None)\n",
    "\n",
    "            else: \n",
    "                repo.append(None)\n",
    "                owner.append(None)\n",
    "                url.append(None)\n",
    "\n",
    "        except IndexError:\n",
    "            # Handle the IndexError when the split method doesn't produce enough elements\n",
    "            repo.append(None)\n",
    "            owner.append(None)\n",
    "            url.append(None)\n",
    "\n",
    "    \n",
    "    github_owner_repo = pd.DataFrame(data= [url, owner, repo]).T\n",
    "    github_owner_repo.columns = ['url','owner', 'repo']\n",
    "    \n",
    "    return github_owner_repo\n",
    "\n",
    "\n",
    "# start the github stats aggregation as its is not in cache, returns 'good to go' whe all the data have been initialized             \n",
    "def start_stats_aggregation(github_df_repos):\n",
    "    start_time = time.time()\n",
    "    for i in range(0,len(github_df_repos['owner'])):\n",
    "        # gettin owner and repo\n",
    "        git_owner = github_df_repos.iloc[i]['owner']\n",
    "        git_repo = github_df_repos.iloc[i]['repo']\n",
    "\n",
    "        # pocking the APi to start gathering the stats\n",
    "        github_code_stats(git_owner, git_repo)\n",
    "\n",
    "        \n",
    "    time.sleep(60)\n",
    "\n",
    "    status = {'start_status':'it did not run yet'}\n",
    "    counting_waiting_loops = 0\n",
    "    \n",
    "    while github_code_stats(github_df_repos.iloc[-1]['owner'], github_df_repos.iloc[-1]['repo'])['status_code'] == 202:\n",
    "        \n",
    "        time.sleep(60)\n",
    "        counting_waiting_loops += 1 \n",
    "        status['start_status'] = f\" passed the {counting_waiting_loops} waiting loop\"\n",
    "     \n",
    "    \n",
    "    else: \n",
    "        status_code = github_code_stats(github_df_repos.iloc[-1]['owner'],github_df_repos.iloc[-1]['repo'])['status_code']\n",
    "        \n",
    "        if status_code in [400,401,402]:\n",
    "            \n",
    "            status['start_status'] = f\"error status code {status_code}\"\n",
    " \n",
    "        elif status_code == 404:\n",
    "    \n",
    "            print('github url not valid or doesnt exist')\n",
    "\n",
    "\n",
    "        elif status_code == 200:\n",
    "            \n",
    "            status['start_status'] = 'good to go'\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            status['start_status'] = 'unknown error'\n",
    "    \n",
    "    return  status['start_status']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sunday_timestamp(week_number, year):\n",
    "    # Create a datetime object for the first day of the given year\n",
    "    first_day = datetime.datetime(year, 1, 1, tzinfo=pytz.utc)\n",
    "    \n",
    "    # Calculate the number of days to the first Sunday of the year\n",
    "    days_to_first_sunday = (6 - first_day.weekday()) % 7\n",
    "    \n",
    "    # Calculate the number of days to the Sunday of the given week\n",
    "    days_to_sunday = (week_number - 1) * 7 + days_to_first_sunday\n",
    "    \n",
    "    # Create a datetime object for the Sunday of the given week\n",
    "    sunday = first_day + datetime.timedelta(days=days_to_sunday)\n",
    "    \n",
    "    # Convert the datetime object to a UTC timestamp\n",
    "    return int(sunday.timestamp())\n",
    "\n",
    "\n",
    "# repo_data in json \n",
    "# start and end date aggregation in number of weeks\n",
    "\n",
    "def timeframing_data(repo_data, start_date_aggregation, end_date_aggregation):\n",
    "    weeks = []\n",
    "    addition = []\n",
    "    deletions = []\n",
    "\n",
    "    for i in range(0,len(repo_data)):\n",
    "        weeks.append(repo_data[i][0])\n",
    "        addition.append(repo_data[i][1])\n",
    "        deletions.append(repo_data[i][2])\n",
    "\n",
    "\n",
    "    week_addition = pd.DataFrame( data = [weeks, addition, deletions]).T\n",
    "\n",
    "    week_addition.columns = ['weeks', 'addition', 'deletions']\n",
    "\n",
    "    additions_by_week = week_addition[(week_addition['weeks']<= sunday_timestamp(start_date_aggregation,2022)) & \n",
    "                  (week_addition['weeks'] > (sunday_timestamp(start_date_aggregation,2022) - end_date_aggregation* 604800 ))]\n",
    "    \n",
    "    return additions_by_week\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01f8ef0",
   "metadata": {},
   "source": [
    "## pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806e63ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "841ecd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample =  df[0:20]['github_project_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2dfe0d6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      https://github.com/socathie/zkML\n",
       "1                  https://github.com/DIMCHERRY/NFT-Ads\n",
       "2                        https://github.com/Energy-Node\n",
       "3         https://github.com/SaveWithBuckets/Buckets_v1\n",
       "4                     https://github.com/pshdev0/dexode\n",
       "5                     https://github.com/pshdev0/dexode\n",
       "6                             https://github.com/anspar\n",
       "7                   https://github.com/Nawarat-Protocol\n",
       "8                           https://github.com/VMLVaske\n",
       "9            https://github.com/AthanorLabs/atomic-swap\n",
       "10                                                  NaN\n",
       "11                        https://github.com/dailyfeeds\n",
       "12                                                  NaN\n",
       "13                              https://github.com/0xpm\n",
       "14               https://github.com/holic/web3-scaffold\n",
       "15             https://github.com/lenstube-xyz/lenstube\n",
       "16          https://github.com/heacare/habitat-sdk-dart\n",
       "17          https://github.com/organizations/MetaportCo\n",
       "18    https://github.com/lxdao-official/myfirstnft-f...\n",
       "19                                                  NaN\n",
       "Name: github_project_url, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c80a46c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from a list get the owner and repo names\n",
    "sample =  df[5:17]['github_project_url']\n",
    "sample = sample[~sample.isna()]\n",
    "owner_repo_names  = get_owner_repo(sample)\n",
    "\n",
    "#clean the none values\n",
    "owner_repo_names = owner_repo_names[~owner_repo_names['repo'].isna()]\n",
    "\n",
    "# poke the github APi to start aggregation of data for the repos we want \n",
    "aggregation_status = start_stats_aggregation(owner_repo_names[['owner', 'repo']])\n",
    "\n",
    "# aqui eu tenho um df com \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "93e58079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good to go'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregation_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f88b78a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>owner</th>\n",
       "      <th>repo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/pshdev0/dexode</td>\n",
       "      <td>pshdev0</td>\n",
       "      <td>dexode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://github.com/AthanorLabs/atomic-swap</td>\n",
       "      <td>AthanorLabs</td>\n",
       "      <td>atomic-swap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://github.com/holic/web3-scaffold</td>\n",
       "      <td>holic</td>\n",
       "      <td>web3-scaffold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://github.com/lenstube-xyz/lenstube</td>\n",
       "      <td>lenstube-xyz</td>\n",
       "      <td>lenstube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://github.com/heacare/habitat-sdk-dart</td>\n",
       "      <td>heacare</td>\n",
       "      <td>habitat-sdk-dart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           url         owner              repo\n",
       "0            https://github.com/pshdev0/dexode       pshdev0            dexode\n",
       "4   https://github.com/AthanorLabs/atomic-swap   AthanorLabs       atomic-swap\n",
       "7       https://github.com/holic/web3-scaffold         holic     web3-scaffold\n",
       "8     https://github.com/lenstube-xyz/lenstube  lenstube-xyz          lenstube\n",
       "9  https://github.com/heacare/habitat-sdk-dart       heacare  habitat-sdk-dart"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sample =  df[5:17]['github_project_url']\n",
    "sample = sample[~sample.isna()]\n",
    "\n",
    "owner_repo_names  = get_owner_repo(sample)\n",
    "\n",
    "owner_repo_names = owner_repo_names[~owner_repo_names['repo'].isna()]\n",
    "\n",
    "owner_repo_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "286b0c2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18744\\588434313.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mdata_json\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgithub_code_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mowner_repo_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'owner'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mowner_repo_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'repo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'repo_data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         df_url_data = timeframing_data(repo_data = data_json, start_date_aggregation = start_date_aggregation, \n\u001b[0m\u001b[0;32m     17\u001b[0m                             end_date_aggregation =  end_date_aggregation)[['weeks', 'addition']]   \n\u001b[0;32m     18\u001b[0m         df_url_data.insert(loc=0,\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18744\\216750898.py\u001b[0m in \u001b[0;36mtimeframing_data\u001b[1;34m(repo_data, start_date_aggregation, end_date_aggregation)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepo_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         \u001b[0mweeks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepo_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m         \u001b[0maddition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepo_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mdeletions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepo_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# if aggregation_status = 'good to go':\n",
    "\n",
    "end_date_aggregation  = 27 # !!!!! precisa ser definido pelo usu[arios]!!!\n",
    "start_date_aggregation = 23 # !!!precisa ser definido pelo usu[arios]!!!\n",
    "\n",
    "\n",
    "# build df to receive data \n",
    "data = []\n",
    "columns_names = ['url','weeks', 'addition']\n",
    "repo_hitorie = pd.DataFrame(data = data, columns = columns_names )\n",
    "\n",
    "\n",
    "for i in range(0, len(owner_repo_names['url'])):\n",
    "    \n",
    "        data_json = github_code_stats(owner_repo_names.iloc[i]['owner'], owner_repo_names.iloc[i]['repo'])['repo_data'] \n",
    "        df_url_data = timeframing_data(repo_data = data_json, start_date_aggregation = start_date_aggregation, \n",
    "                            end_date_aggregation =  end_date_aggregation)[['weeks', 'addition']]   \n",
    "        df_url_data.insert(loc=0,\n",
    "          column='url',\n",
    "          value= i )\n",
    "        repo_data = pd.concat([repo_hitorie, df_url_data])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a209d160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0d98bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url,weeks</th>\n",
       "      <th>additions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [url,weeks, additions]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_historie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e248b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# repo_data in json \n",
    "# start and end date aggregation in number of weeks\n",
    "def timeframing_data(repo_data, start_date_aggregation, end_date_aggregation):\n",
    "    weeks = []\n",
    "    addition = []\n",
    "    deletions = []\n",
    "\n",
    "    for i in range(0,len(repo_data)):\n",
    "        weeks.append(repo_data[i][0])\n",
    "        addition.append(repo_data[i][1])\n",
    "        deletions.append(repo_data[i][2])\n",
    "\n",
    "\n",
    "    week_addition = pd.DataFrame( data = [weeks, addition, deletions]).T\n",
    "\n",
    "    week_addition.columns = ['weeks', 'addition', 'deletions']\n",
    "\n",
    "    additions_by_week = week_addition[(week_addition['weeks']<= sunday_timestamp(start_date_aggregation,2022)) & \n",
    "                  (week_addition['weeks'] > (sunday_timestamp(start_date_aggregation,2022) - end_date_aggregation* 604800 ))]\n",
    "    \n",
    "    return additions_by_week\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dd865a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78f7f64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e13d379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a727a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c180e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02551e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11e3159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df95266b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e49fce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bb1a36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0b1f92de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 59 API requests remaining\n",
      "API request failed with status code 401\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# remaining rate limit\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Define API endpoint and personal access token\n",
    "url = 'https://api.github.com/user/repos'\n",
    "headers = {'Authorization': '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'}\n",
    "\n",
    "# Make API request\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Access X-RateLimit-Remaining header\n",
    "remaining_requests = int(response.headers['X-RateLimit-Remaining'])\n",
    "print(f'You have {remaining_requests} API requests remaining')\n",
    "\n",
    "# Handle API response\n",
    "if response.status_code == 200:\n",
    "    data = json.loads(response.text)\n",
    "    # Process data as needed\n",
    "else:\n",
    "    print(f'API request failed with status code {response.status_code}')\n",
    "\n",
    "# Wait if rate limit is close to being reached\n",
    "if remaining_requests < 10:\n",
    "    print('Rate limit approaching. Waiting before making additional requests...')\n",
    "    time.sleep(60)  # Wait for 60 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ced0efa9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Server': 'GitHub.com', 'Date': 'Sat, 15 Apr 2023 14:54:23 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '149', 'X-GitHub-Media-Type': 'github.v3; format=json', 'x-github-api-version-selected': '2022-11-28', 'X-RateLimit-Limit': '60', 'X-RateLimit-Remaining': '18', 'X-RateLimit-Reset': '1681573299', 'X-RateLimit-Used': '42', 'X-RateLimit-Resource': 'core', 'Access-Control-Expose-Headers': 'ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Resource, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, X-GitHub-SSO, X-GitHub-Request-Id, Deprecation, Sunset', 'Access-Control-Allow-Origin': '*', 'Strict-Transport-Security': 'max-age=31536000; includeSubdomains; preload', 'X-Frame-Options': 'deny', 'X-Content-Type-Options': 'nosniff', 'X-XSS-Protection': '0', 'Referrer-Policy': 'origin-when-cross-origin, strict-origin-when-cross-origin', 'Content-Security-Policy': \"default-src 'none'\", 'Vary': 'Accept-Encoding, Accept, X-Requested-With', 'X-GitHub-Request-Id': 'A3CC:51EF:11E51AA:2511736:643ABA9E'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(url, headers=headers).headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f07240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
